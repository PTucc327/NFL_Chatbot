# -*- coding: utf-8 -*-
"""NFLChatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fyyodDIEn9KUhDgVU0Jtn6K-8m8aYIIL
"""

!pip install beautifulsoup4 requests gradio

# nfl_chatbot_clickable_news_fixed.py
# Requirements: pip install requests gradio
# Clickable news links (Markdown) + integrated NFL Chatbot features.

import requests
import datetime
import time
import gradio as gr
from typing import Optional, Tuple, Dict, Any, List
import re
import pandas as pd
# timezone helper (Python 3.9+)
try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None

# -------------------------
# Config & constants
# -------------------------
REQUEST_TIMEOUT = 10
CACHE_TTL = 24 * 3600

ESPN_SCOREBOARD_URL = "https://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard"
ESPN_NEWS_URL = "https://site.api.espn.com/apis/site/v2/sports/football/nfl/news"
ESPN_TEAMS_URL = "https://site.api.espn.com/apis/site/v2/sports/football/nfl/teams"
ESPN_STANDINGS_URL = "https://site.api.espn.com/apis/v2/sports/football/nfl/standings"
SLEEPER_PLAYERS_URL = "https://api.sleeper.app/v1/players/nfl"
SLEEPER_STATS_URL_TEMPLATE = "https://api.sleeper.app/v1/stats/nfl/regular/{year}"

# Global constants for Player Lookup
COMMON_TEAM_NAMES = [
    "giants","cowboys","eagles","commanders","49ers","seahawks","rams","cardinals",
    "packers","bears","lions","vikings","saints","falcons","buccaneers","panthers",
    "chiefs","broncos","raiders","chargers","bills","patriots","dolphins","jets",
    "ravens","bengals","steelers","browns","colts","titans","jaguars","texans"
]
# Use uppercase for POSITIONS set
POSITIONS = {"QB","RB","WR","TE","K","P","DE","DT","LB","CB","S","OL","G","T","C"}

# -------------------------
# Network helper
# -------------------------
def fetch_json(url: str, params: dict = None):
    try:
        resp = requests.get(url, params=params, timeout=REQUEST_TIMEOUT)
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        return {"__error": str(e)}

# -------------------------
# ISO datetime parse helper
# -------------------------
def _parse_iso_datetime(s: Optional[str]) -> Optional[datetime.datetime]:
    if not s:
        return None
    try:
        if s.endswith("Z"):
            s2 = s[:-1] + "+00:00"
        else:
            s2 = s
        dt = datetime.datetime.fromisoformat(s2)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=datetime.timezone.utc)
        return dt
    except Exception:
        for fmt in ("%Y-%m-%dT%H:%M:%S.%fZ", "%Y-%m-%dT%H:%M:%SZ"):
            try:
                return datetime.datetime.strptime(s, fmt).replace(tzinfo=datetime.timezone.utc)
            except Exception:
                continue
    return None

# -------------------------
# ESPN team cache (id -> metadata)
# -------------------------
_team_cache = {}
_team_cache_last = 0

def _ensure_team_cache():
    """Populate _team_cache with keys mapping to team metadata (id, displayName, abbr, slug, schedule_url)."""
    global _team_cache, _team_cache_last
    now = time.time()
    if _team_cache and now - _team_cache_last < CACHE_TTL:
        return
    _team_cache = {}
    data = fetch_json(ESPN_TEAMS_URL)
    if "__error" in data:
        _team_cache_last = now
        return
    teams = []
    if isinstance(data, dict):
        try:
            leagues = data.get("sports", [])[0].get("leagues", [])
            if leagues:
                teams = leagues[0].get("teams", [])
        except Exception:
            teams = data.get("teams", []) or []
    elif isinstance(data, list):
        teams = data

    for item in teams:
        team_obj = item.get("team") if isinstance(item, dict) and "team" in item else item
        if not isinstance(team_obj, dict):
            continue
        team_id = team_obj.get("id")
        display = team_obj.get("displayName") or team_obj.get("name") or team_obj.get("shortDisplayName")
        abbr = team_obj.get("abbreviation") or ""
        slug = team_obj.get("slug") or ""
        if not team_id:
            continue
        schedule_url = f"https://site.api.espn.com/apis/site/v2/sports/football/nfl/teams/{team_id}/schedule"
        meta = {
            "id": str(team_id),
            "displayName": display,
            "abbr": abbr,
            "slug": slug,
            "schedule_url": schedule_url
        }
        # store under several lookup keys (lowercased)
        keys = set()
        if display:
            keys.add(display.lower())
        if abbr:
            keys.add(abbr.lower())
        if slug:
            keys.add(slug.lower())
        for k in keys:
            _team_cache[k] = meta
        # also store under the numeric id string
        _team_cache[str(team_id)] = meta
    _team_cache_last = now

def _find_team(team_name: Optional[str]):
    """Return ESPN team metadata (with id) by fuzzy matching against _team_cache."""
    if not team_name:
        return None
    _ensure_team_cache()
    q = team_name.strip().lower()
    # exact key
    if q in _team_cache:
        return _team_cache[q]
    # try displayName match or substring
    for k, v in _team_cache.items():
        dn = (v.get("displayName") or "").lower()
        ab = (v.get("abbreviation") or "").lower()
        slug = (v.get("slug") or "").lower()
        if q == k or q in k or q in dn or q == ab or q in slug or q in dn.split():
            return v
    return None

# -------------------------
# Live scores
# -------------------------
def get_live_scores(team_name: Optional[str] = None) -> str:
    data = fetch_json(ESPN_SCOREBOARD_URL)
    if "__error" in data:
        return f"Error fetching scores: {data['__error']}"
    events = data.get("events", []) or []
    if not isinstance(events, list):
        return "No games found."
    team_q = team_name.lower() if team_name else None
    lines = []
    for ev in events:
        try:
            comp = ev.get("competitions", [])[0]
            comps = comp.get("competitors", [])
            if len(comps) < 2:
                continue
            left = comps[0]
            right = comps[1]
            n0 = left.get("team", {}).get("displayName") or ""
            n1 = right.get("team", {}).get("displayName") or ""
            s0 = left.get("score", "") or ""
            s1 = right.get("score", "") or ""
            status = comp.get("status", {}).get("type", {}).get("description") or ""
            line = f"{n0} {s0} - {n1} {s1}" + (f" ({status})" if status else "")
            if not team_q or team_q in n0.lower() or team_q in n1.lower():
                lines.append(line)
        except Exception:
            continue
    return "\n".join(lines) if lines else (f"No live scores for '{team_name}'" if team_name else "No live scores found.")

# -------------------------
# Next / Last game
# -------------------------
def get_next_game(team_name: Optional[str]) -> str:
    if not team_name:
        return "Please include a team name (e.g., 'Chiefs')."
    team_meta = _find_team(team_name)
    if not team_meta:
        return f"Couldn't resolve team '{team_name}'. Try 'Chiefs' or 'Bills'.'"
    sched_url = team_meta.get("schedule_url")
    data = fetch_json(sched_url)
    if "__error" in data:
        return f"Error fetching schedule: {data['__error']}"
    events = data.get("events") or data.get("items") or data.get("schedule") or []
    if not isinstance(events, list):
        evs = []
        for v in data.values():
            if isinstance(v, list):
                evs = v
                break
        events = evs
    now = datetime.datetime.now(datetime.timezone.utc)
    future = []
    for ev in events:
        date_str = ev.get("date") or ev.get("startDate") or ev.get("originalDate")
        dt = _parse_iso_datetime(date_str)
        if not dt:
            continue
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=datetime.timezone.utc)
        if dt > now:
            future.append((dt, ev))
    if not future:
        return f"No upcoming games found for {team_meta.get('displayName')}."
    future.sort(key=lambda x: x[0])
    dt, ev = future[0]
    comp = ev.get("competitions", [ev])[0] if ev else ev
    competitors = comp.get("competitors", [])
    opponent = "Unknown"
    homeaway = ""
    for c in competitors:
        name = c.get("team", {}).get("displayName") or ""
        if team_meta.get("displayName") and team_meta["displayName"].lower() in name.lower():
            homeaway = c.get("homeAway") or ""
            continue
        opponent = name
    if ZoneInfo:
        try:
            local = dt.astimezone(ZoneInfo("America/New_York"))
            tstr = local.strftime("%a, %b %d %I:%M %p %Z")
        except Exception:
            tstr = dt.isoformat()
    else:
        tstr = dt.isoformat()
    ha = "at home" if homeaway == "home" else "away" if homeaway == "away" else ""
    return f"Next game for {team_meta.get('displayName')}: {ha} vs {opponent} on {tstr}."

def get_last_game(team_name: Optional[str]) -> str:
    if not team_name:
        return "Please include a team name (e.g., 'Patriots')."
    team_meta = _find_team(team_name)
    if not team_meta:
        return f"Couldn't resolve team '{team_name}'."
    data = fetch_json(team_meta.get("schedule_url"))
    if "__error" in data:
        return f"Error fetching schedule: {data['__error']}"
    events = data.get("events") or data.get("items") or data.get("schedule") or []
    if not isinstance(events, list):
        evs = []
        for v in data.values():
            if isinstance(v, list):
                evs = v
                break
        events = evs
    now = datetime.datetime.now(datetime.timezone.utc)
    past = []
    for ev in events:
        date_str = ev.get("date") or ev.get("startDate") or ev.get("originalDate")
        dt = _parse_iso_datetime(date_str)
        if not dt:
            continue
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=datetime.timezone.utc)
        if dt <= now:
            past.append((dt, ev))
    if not past:
        return f"No past games found for {team_meta.get('displayName')}."
    past.sort(key=lambda x: x[0], reverse=True)
    dt, ev = past[0]
    comp = ev.get("competitions", [ev])[0] if ev else ev
    lines = []
    competitors = comp.get("competitors", [])
    for c in competitors:
        name = c.get("team", {}).get("displayName") or ""
        score = c.get("score") or ""
        lines.append(f"{name} {score}")
    if ZoneInfo:
        try:
            local = dt.astimezone(ZoneInfo("America/New_York"))
            dstr = local.strftime("%a, %b %d %I:%M %p %Z")
        except Exception:
            dstr = dt.isoformat()
    else:
        dstr = dt.isoformat()
    return f"Last game for {team_meta.get('displayName')} on {dstr}: " + " - ".join(lines)

# -------------------------
# News (clickable Markdown links) - robust team-specific + fallback
# -------------------------

def _normalize_team_tokens(team_entry: dict) -> list:
    """
    Build a list of lowercase tokens to match against article text.
    Includes displayName pieces, abbreviation, slug, city, short names.
    """
    tokens = set()
    if not team_entry:
        return []
    dn = (team_entry.get("displayName") or "") or ""
    abbr = (team_entry.get("abbreviation") or "") or ""
    slug = (team_entry.get("slug") or "") or ""
    # Break display name into words, e.g., "New England Patriots" -> ["new", "england","patriots"]
    for part in re.split(r'[\s\-]+', dn.strip().lower()):
        if part:
            tokens.add(part)
    # add common patterns
    if abbr:
        tokens.add(abbr.lower())
    if slug:
        # slug often like "new-england-patriots" -> add parts and whole slug
        for part in slug.split("-"):
            if part:
                tokens.add(part.lower())
        tokens.add(slug.lower())
    # also add full display name as token
    if dn:
        tokens.add(dn.strip().lower())
    return sorted(tokens, key=lambda x: -len(x))  # longer tokens first

# Handle ambiguous team names (e.g., Giants, Jets) by mapping to unique keywords
TEAM_KEYWORD_MAP = {
    "giants": ["new york giants", "ny giants", "n.y. giants", "big blue", "metlife stadium"],
    "jets": ["new york jets", "ny jets", "gang green", "metlife stadium"],
    "patriots": ["new england patriots", "foxborough", "gillette stadium"],
    "cowboys": ["dallas cowboys", "america's team", "at&t stadium"],
}

def _article_matches_team(article: dict, team_entry: dict, team_tokens: list) -> bool:
    """
    Return True if we consider this article to be about the team.
    Checks:
      - explicit fields (article['teams'], 'related' tags, 'keywords', 'categories')
      - title/description/body includes team tokens (word-boundary or partial)
      - link canonical / href / url contains team slug or tokens
      - contextual matching for ambiguous teams (Giants, Jets, etc.)
    """
    if not article or not team_entry:
        return False

    # Handle ambiguous team names like 'Giants', 'Jets'
    team_name = team_entry.get("displayName", "").lower()
    last_word = team_name.split()[-1] if team_name else ""
    extra_tokens = TEAM_KEYWORD_MAP.get(last_word, [])
    team_tokens = list(set(team_tokens + extra_tokens))

    # 1) Structured fields (teams, keywords, tags)
    for key in ("teams", "related", "relatedTeams", "keywords", "subjects", "categories", "tags"):
        val = article.get(key)
        if isinstance(val, list):
            for it in val:
                if isinstance(it, dict):
                    name = (it.get("name") or it.get("displayName") or "").lower()
                    if any(tok in name for tok in team_tokens):
                        return True
                elif isinstance(it, str):
                    if any(tok in it.lower() for tok in team_tokens):
                        return True

    # 2) Combine title/description/body
    text_parts = []
    for f in ("headline", "title", "description", "name", "summary", "caption"):
        v = article.get(f)
        if isinstance(v, str):
            text_parts.append(v)
    content = article.get("content")
    if isinstance(content, dict):
        for k in ("text", "html", "body"):
            if isinstance(content.get(k), str):
                text_parts.append(content.get(k))
    combined = " ".join(text_parts).lower()

    if not combined:
        for k, v in article.items():
            if isinstance(v, str):
                combined += " " + v.lower()

    # 3) URL/canonical fields
    for link_key in ("canonical", "link", "href", "url"):
        val = article.get(link_key)
        if isinstance(val, str):
            val_l = val.lower()
            if team_entry.get("slug") and team_entry["slug"].lower() in val_l:
                return True
            if any(tok in val_l for tok in team_tokens):
                return True

    # 4) Nested link objects
    links = article.get("links")
    if isinstance(links, dict):
        for sub in ("web", "website", "canonical"):
            node = links.get(sub)
            if isinstance(node, dict):
                href = node.get("href") or node.get("url") or ""
                if isinstance(href, str):
                    href_l = href.lower()
                    if team_entry.get("slug") and team_entry["slug"].lower() in href_l:
                        return True
                    if any(tok in href_l for tok in team_tokens):
                        return True

    # 5) Word or partial token matches (stronger logic)
    if combined:
        text = combined.lower()
        # exact or multi-word hits
        full_name = team_entry.get("displayName", "").lower()
        slug = team_entry.get("slug", "").lower()
        if full_name and full_name in text:
            return True
        if slug and slug in text:
            return True

        # Allow 2+ token matches (e.g., "new" + "england")
        hits = sum(tok in text for tok in team_tokens)
        if hits >= 2:
            return True

        # Single word fallback with boundaries
        for tok in team_tokens:
            t = re.escape(tok)
            if re.search(rf"\b{t}\b", text):
                return True

    return False


def get_nfl_news(team_name: Optional[str] = None) -> str:
    """
    Fetch team-specific or league news, then perform robust local filtering by team tokens.
    Returns up to 6 Markdown links. If no team-specific articles are found,
    returns up to 4 general league headlines with a small note.
    """
    # 1) attempt to call team feed if team resolves
    team_entry = None
    if team_name and team_name.lower() not in ("nfl", "league", "football"):
        team_entry = _find_team(team_name)

    news_data = None
    if team_entry and team_entry.get("id"):
        url = f"https://site.api.espn.com/apis/site/v2/sports/football/nfl/teams/{team_entry['id']}/news"
        news_data = fetch_json(url)
        # if the team endpoint is empty or error, fallback to league feed
        if "__error" in news_data or not isinstance(news_data, dict) or not any(isinstance(news_data.get(k), (list, dict)) for k in ["articles","items","news","feed","headlines"]):
            news_data = None

    # 2) fallback to league feed
    if not news_data:
        news_data = fetch_json(ESPN_NEWS_URL)
        if "__error" in news_data:
            return f"Error fetching news: {news_data['__error']}"

    # 3) collect article objects from all known locations
    possible_keys = ["articles", "items", "news", "feed", "headlines", "story", "section"]
    articles = []
    if isinstance(news_data, dict):
        for key in possible_keys:
            val = news_data.get(key)
            if isinstance(val, list):
                articles.extend(val)
            elif isinstance(val, dict):
                # some structures have nested lists inside a dict
                for subk in possible_keys:
                    sub = val.get(subk)
                    if isinstance(sub, list):
                        articles.extend(sub)
    elif isinstance(news_data, list):
        articles = news_data[:]

    # other nested fallbacks
    for subkey in ("content","data"):
        sub = news_data.get(subkey) if isinstance(news_data, dict) else None
        if isinstance(sub, dict):
            for key in possible_keys:
                val = sub.get(key)
                if isinstance(val, list):
                    articles.extend(val)

    # final fallback gather: any top-level list values
    if not articles and isinstance(news_data, dict):
        for v in news_data.values():
            if isinstance(v, list):
                articles.extend(v)

    if not articles:
        return f"No recent news found for '{team_name or 'NFL'}'."

    # 4) if team requested: filter articles robustly using helper
    filtered = []
    if team_entry:
        team_tokens = _normalize_team_tokens(team_entry)
        for art in articles:
            try:
                if _article_matches_team(art, team_entry, team_tokens):
                    filtered.append(art)
            except Exception:
                # defensive: skip bad article
                continue
    # if filtering produced results, use them; otherwise we'll return labeled general headlines
    use_articles = filtered if filtered else articles

    # 5) format Markdown headlines (limit results)
    md_lines = []
    limit = 6 if filtered else 4  # if filtered, up to 6; if general fallback, show fewer and label
    count = 0
    for a in use_articles:
        if count >= limit:
            break
        title = a.get("headline") or a.get("title") or a.get("description") or a.get("name")
        if not title:
            continue
        # locate best link
        link = ""
        links = a.get("links") if isinstance(a.get("links"), dict) else None
        if isinstance(links, dict):
            web = links.get("web") or links.get("website")
            if isinstance(web, dict) and web.get("href"):
                link = web.get("href")
        if not link:
            link = a.get("canonical") or a.get("link") or a.get("href") or ""
        if link:
            safe_title = title.replace("]", "\\]")
            md_lines.append(f"- [{safe_title}]({link})")
        else:
            md_lines.append(f"- {title}")
        count += 1

    if not md_lines:
        return f"No recent news found for '{team_name or 'NFL'}'."

    # 6) if we tried filtering but found no matches, add a clarifying header
    if team_entry and not filtered:
        header = f"‚ö†Ô∏è No team-specific matches found for **{team_entry.get('displayName')}**. Showing top NFL headlines instead:\n\n"
        return header + "\n".join(md_lines)
    return "\n".join(md_lines)

# -------------------------
# Sleeper player cache + stats
# -------------------------
_player_cache = {}
_player_cache_last = 0

def _ensure_player_cache():
    global _player_cache, _player_cache_last
    now = time.time()
    if _player_cache and now - _player_cache_last < CACHE_TTL:
        return
    data = fetch_json(SLEEPER_PLAYERS_URL)
    _player_cache = {}
    if isinstance(data, dict):
        for pid, info in data.items():
            if isinstance(info, dict):
                _player_cache[str(pid)] = info
    elif isinstance(data, list):
        for item in data:
            pid = item.get("player_id") or item.get("id") or item.get("playerId")
            if pid:
                _player_cache[str(pid)] = item
    _player_cache_last = now

# --- START OF UPDATED FANTASY STATS FUNCTION ---
def get_fantasy_player_stats(query_name: Optional[str] = None) -> str:
    _ensure_player_cache()
    if not query_name:
        return "Please specify a player name. Example: 'Fantasy stats for Patrick Mahomes'"

    # 1. Clean the query using the robust player lookup helpers
    q_norm = _normalize_query(query_name)
    pos_hint, q_name_part = _detect_position_and_strip(q_norm)
    # Note: Skipping team detection for fantasy stats lookup simplicity/speed.
    name_tokens = [tok for tok in q_name_part.split() if tok]

    if not name_tokens:
        return "Could not determine player name from query."

    year = datetime.datetime.now().year
    url = SLEEPER_STATS_URL_TEMPLATE.format(year=year)
    stats = fetch_json(url)
    if "__error" in stats:
        return f"Error fetching fantasy stats: {stats['__error']}"

    results = []
    player_cache = globals().get("_player_cache") or {}

    if isinstance(stats, dict):
        for pid, pdata in stats.items():
            meta = player_cache.get(str(pid), {})

            # 2. Match the player name using the robust token matching helper
            if not _player_matches_name(meta, name_tokens):
                continue

            # 3. Filter by position hint (if provided)
            if pos_hint and (meta.get("position") or "").upper() != pos_hint:
                 continue

            # 4. Extract data and format result
            pname = (meta.get("full_name") or f"{meta.get('first_name','')} {meta.get('last_name','')}")
            pts = pdata.get("pts_ppr") or pdata.get("fantasy_points") or pdata.get("points") or "N/A"
            position = (meta.get("position") or "N/A").upper()
            team = meta.get("team") or "FA" # FA for Free Agent

            results.append(f"{pname} ({position}, {team}): **{pts} PPR**")

    # Remove duplicates and limit the results to the top 5
    unique_results = sorted(list(set(results)))
    return "\n".join(unique_results[:5]) if unique_results else f"No fantasy stats found for '{query_name}'. (Cleaned name: '{' '.join(name_tokens)}')"
# --- END OF UPDATED FANTASY STATS FUNCTION ---


# -------------------------
# Simplified team standings (team-only)
# -------------------------
def get_team_standings(team_name: Optional[str] = None, division: Optional[str] = None) -> str:
    if not team_name:
        return "Please include a team name (e.g., 'Bills standings')."
    team = _find_team(team_name)
    if not team:
        return f"Couldn't find team '{team_name}'."
    data = fetch_json(ESPN_STANDINGS_URL)
    if "__error" in data:
        return f"Error fetching standings: {data['__error']}"
    def extract_entries(node):
        out = []
        if isinstance(node, dict):
            if "standings" in node and "entries" in node["standings"]:
                out.extend(node["standings"]["entries"])
            for k in ("children","groups"):
                if isinstance(node.get(k), list):
                    for child in node[k]:
                        out.extend(extract_entries(child))
        elif isinstance(node, list):
            for it in node:
                out.extend(extract_entries(it))
        return out
    entries = extract_entries(data)
    for e in entries:
        t = e.get("team", {}) or {}
        name = (t.get("displayName") or t.get("shortDisplayName") or "").lower()
        if team_name.lower() in name:
            stats = e.get("stats", []) or []
            wins = int(float(next((s.get("value") for s in stats if s.get("name") == "wins"), 0)))
            losses = int(float(next((s.get("value") for s in stats if s.get("name") == "losses"), 0)))
            ties = int(float(next((s.get("value") for s in stats if s.get("name") == "ties"), 0)))
            pct = next((s.get("displayValue") for s in stats if s.get("name") == "winPercent"), "")
            return f"{t.get('displayName')} ‚Äî {wins}-{losses}-{ties}" + (f" ({pct} win pct)" if pct else "")
    return f"No standings data found for '{team_name}'."

# -------------------------
# Team detection helper
# -------------------------
# *** START OF OPTIMIZED detect_team_name ***
def detect_team_name(text: str) -> Optional[str]:
    """
    Return a canonical team name (displayName) suitable for other functions.
    Optimized by checking cache keys first.
    """
    if not text or not text.strip():
        return None

    ui = text.strip().lower()

    # 1. Ensure cache is populated
    _ensure_team_cache()

    # 2. Check the user input against all known cache keys (abbr, slug, display name)
    team_cache = globals().get("_team_cache") or {}

    # Check if a single word in the input is an exact cache key
    for word in ui.split():
        if word in team_cache:
            # Found an exact key match! Return its canonical displayName.
            return team_cache[word].get("displayName")

    # 3. Fallback to the robust fuzzy search (using your existing logic)
    team_meta = _find_team(ui)

    if team_meta:
        # Return the canonical display name found by the fuzzy match
        return team_meta.get("displayName")

    return None
# *** END OF OPTIMIZED detect_team_name ***


# -------------------------
# Player Stats (Incorporated Fixed Logic)
# -------------------------
# Initialize once
player_df = pd.DataFrame(columns=["Name", "Age", "Position", "Team", "College", "Years_in_NFL"])

def save_player_profile(profile_dict: Dict[str, Any]):
    global player_df
    player_df = pd.concat([player_df, pd.DataFrame([profile_dict])], ignore_index=True)

# Helper functions for robust player lookup

def _normalize_query(q: str) -> str:
    q = q.lower().strip()
    # remove punctuation
    q = re.sub(r"[^a-z0-9\s]", " ", q)
    # collapse whitespace
    q = re.sub(r"\s+", " ", q).strip()

    # --- UPDATED: Added more human-like filler words to strip ---
    for w in (
        "who is", "tell me about", "show me", "give me",
        "player", "on the", "in the", "from", "team", "the",
        "for", "fantasy", "stats", "ppr", "pts",
        "qb for", "wr for", "rb for", "te for", "k for"
    ):
        # Use word boundaries (\b) to avoid removing parts of a name (e.g., 'who is' vs 'whis')
        # but since we are replacing single-word tokens in a loop, a simple replace is faster.
        q = q.replace(w, " ")

    q = re.sub(r"\s+", " ", q).strip()
    return q

def _detect_position_and_strip(query: str) -> Tuple[Optional[str], str]:
    """Return (position_hint_or_None, query_without_position)."""
    words = query.split()
    pos = None
    remaining = []
    for w in words:
        if w.upper() in POSITIONS:
            pos = w.upper()
        else:
            remaining.append(w)
    return pos, " ".join(remaining)

# NOTE: _detect_team_from_query relies on the global _team_cache which is handled by _ensure_team_cache()

def _detect_team_from_query(query: str, debug=False) -> Optional[str]:
    """
    Detect team token either from COMMON_TEAM_NAMES or from _team_cache (abbr/displayName/slug).
    Returns normalized team_token (like 'bills' or 'buf') or None.
    """
    # quick local check
    for t in COMMON_TEAM_NAMES:
        if t in query:
            if debug: print("team detected (common list):", t)
            return t

    # try to find team via team cache (if available)
    try:
        _ensure_team_cache()
    except Exception:
        pass

    # search _team_cache keys/values for matches
    for k, v in (globals().get("_team_cache") or {}).items():
        dn = (v.get("displayName") or "").lower()
        ab = (v.get("abbr") or "").lower()
        slug = (v.get("slug") or "").lower()
        if dn and dn in query:
            if debug: print("team detected (team_cache displayName):", dn)
            return dn.split()[-1] if " " in dn else dn
        if ab and ab.lower() in query:
            if debug: print("team detected (team_cache abbr):", ab)
            return ab
        if slug and slug in query:
            if debug: print("team detected (team_cache slug):", slug)
            return slug.split("-")[-1] if "-" in slug else slug

    return None

def _player_matches_name(info: Dict[str, Any], name_tokens: List[str]) -> bool:
    """Check if all name tokens are present in player's name fields."""
    first = (info.get("first_name") or "").lower().strip()
    last = (info.get("last_name") or "").lower().strip()
    full = (info.get("full_name") or f"{first} {last}").lower().strip()
    if not full:
        return False
    # All tokens must be present in the full name string
    return all(tok in full for tok in name_tokens)

def _player_matches_team(info: Dict[str, Any], team_filter: str) -> bool:
    """Check if player's team matches the normalized team filter (abbr, full, or short name)."""
    if not team_filter:
        return True
    team_field = (info.get("team") or "").lower()
    if team_filter in team_field:
        return True
    try:
        _ensure_team_cache()
        for k, v in (globals().get("_team_cache") or {}).items():
            dn = (v.get("displayName") or "").lower()
            ab = (v.get("abbr") or "").lower()
            slug = (v.get("slug") or "").lower()
            if team_filter == ab or team_filter in dn or team_filter in slug:
                if ab and ab in team_field: return True
                if dn and dn.split()[-1] in team_field: return True
    except Exception:
        pass
    return False


def get_player_profile_smart(user_input: str, debug: bool=False) -> str:
    """
    Robust player lookup:
      - normalize input
      - extract position hint (optional)
      - extract team hint (optional)
      - gather all name matches, then filter by position/team if provided
      - save matched profiles to player_df (internal)
      - return a readable string (single profile or short list)
    """
    try:
        _ensure_player_cache()
    except Exception as e:
        if debug: print(f"Error calling _ensure_player_cache: {e}")
        pass

    if not user_input or not user_input.strip():
        return "Please provide a player name."

    q = _normalize_query(user_input)
    if debug: print("normalized query:", q)

    pos_hint, q = _detect_position_and_strip(q)
    if debug: print("pos_hint:", pos_hint, "remaining:", q)

    team_hint = _detect_team_from_query(q, debug=debug)
    if team_hint:
        q = q.replace(team_hint, " ").strip()
        q = re.sub(r"\s+", " ", q)
    if debug: print("team_hint:", team_hint, "name part:", q)

    name_tokens = [tok for tok in q.split() if tok]
    if not name_tokens:
        return "Please include the player's name."

    matches = []
    player_cache = globals().get("_player_cache") or {}

    for pid, info in player_cache.items():
        try:
            if not _player_matches_name(info, name_tokens):
                continue
            if pos_hint:
                if (info.get("position") or "").upper() != pos_hint:
                    continue
            if team_hint and not _player_matches_team(info, team_hint):
                continue
            matches.append(info)
        except Exception:
            continue

    if debug:
        print("matches found:", len(matches))
        for m in matches[:6]:
            fn = (m.get("full_name") or f"{m.get('first_name','')} {m.get('last_name','')}").strip()
            print(" -", fn, m.get("position"), m.get("team"))

    if not matches:
        return f"Player '{user_input}' not found."

    # Save matched profiles in dataframe and prepare outputs
    outputs = []
    for p in matches:
        full_name = (p.get("full_name") or f"{p.get('first_name','')} {p.get('last_name','')}").strip().title()
        profile = {
            "Name": full_name,
            "Age": p.get("age", "N/A"),
            "Position": (p.get("position") or "N/A").upper(),
            "Team": p.get("team", "N/A"),
            "College": p.get("college", "N/A"),
            "Years_in_NFL": p.get("years_exp", "N/A")
        }
        save_player_profile(profile)
        outputs.append(profile)

    # If exactly one found -> return formatted text for it
    if len(outputs) == 1:
        p = outputs[0]
        return (
            f"**Name:** {p['Name']}\n"
            f"- **Age:** {p['Age']}\n"
            f"- **Position:** {p['Position']}\n"
            f"- **Team:** {p['Team']}\n"
            f"- **College:** {p['College']}\n"
            f"- **Years in NFL:** {p['Years_in_NFL']}"
        )

    # multiple matches -> short list
    lines = ["Multiple players found:"]
    # Show at most 5 matches for brevity
    for p in outputs[:5]:
        lines.append(f"- {p['Name']} ({p['Position']} ‚Äî {p['Team']})")

    if len(outputs) > 5:
        lines.append(f"(...{len(outputs) - 5} more matches)")

    return "\n".join(lines)


# -------------------------
# Chat router
# -------------------------
# *** START OF UPDATED nfl_chatbot FANTASY BLOCK ***
def nfl_chatbot(user_input: str, history=None) -> str:
    if not user_input or not user_input.strip():
        return "Ask me about scores, news, next/last games, standings, or fantasy stats. Example: 'Bills record' or 'When do the Chiefs play next?'"
    ui = user_input.strip().lower()

    # scores
    if "score" in ui or "scores" in ui:
        t = detect_team_name(ui)
        return get_live_scores(t)

    # news (clickable)
    if "news" in ui or "article" in ui or "headline" in ui:
        t = detect_team_name(ui)
        return get_nfl_news(t)

    # standings (team-only)
    if "standing" in ui or "record" in ui or "rank" in ui:
        t = detect_team_name(ui)
        if t:
            return get_team_standings(team_name=t)
        return "Which team's record would you like? Example: 'Bills record'"

    # next / upcoming
    if ("next" in ui or "upcoming" in ui or ("when" in ui and "play" in ui)) and ("play" in ui or "game" in ui or "schedule" in ui):
        t = detect_team_name(ui)
        if not t:
            return "Please include a team name for 'next game' queries (e.g., 'Next game for Chiefs')."
        return get_next_game(t)

    # last / previous
    if any(k in ui for k in ["last", "previous", "recent"]) and ("game" in ui or "played" in ui):
        t = detect_team_name(ui)
        if not t:
            return "Please include a team name for 'last game' queries (e.g., 'Last game for Bills')."
        return get_last_game(t)

    # fantasy player stats
    if "fantasy" in ui or "pts" in ui or "ppr" in ui or "stats for" in ui:
        # Pass the full user input to the smart function for internal parsing/cleaning.
        return get_fantasy_player_stats(user_input)

    # Player info (now using the smart, fixed logic)
    if "who is" in ui or "player" in ui or "about" in ui or "profile" in ui:
        # Extract the relevant name/query part after removing trigger phrases
        q = _normalize_query(user_input)
        if not q:
            return "Please provide a player's name and optional team/position."
        return get_player_profile_smart(q, debug=False) # Pass the cleaned query to the smart lookup

    # fallback help
    return ("I can fetch live scores, NFL news (clickable links), team next/last games, team records, and fantasy player stats.\n"
        "Examples:\n - 'Give me NFL news'\n - 'Patriots news'\n - 'Bills record'\n - 'When do the Chiefs play next?'\n - 'Fantasy stats for Patrick Mahomes'\n - 'Who is Josh Allen?'")
# *** END OF UPDATED nfl_chatbot FANTASY BLOCK ***
# -------------------------
# Gradio Chat UI
# -------------------------
chat = gr.ChatInterface(
    fn=nfl_chatbot,
    title="üèà NFL Chatbot (Clickable News) - Fixed",
    description="Ask about live scores, news (clickable links), schedules, standings, and robust player profiles (e.g., 'Who is Josh Allen QB Bills').",
    examples=[
        ["Give me NFL news"],
        ["Patriots news"],
        ["Bills record"],
        ["When do the Giants play next?"],
        ["Fantasy stats for Patrick Mahomes"],
        ["Who is Josh Allen QB Bills?"]
    ]
)

if __name__ == "__main__":
    chat.launch()

